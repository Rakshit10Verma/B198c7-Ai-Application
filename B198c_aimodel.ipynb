{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a90900679a841458109f1dcb0f26a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0acf96853034778bc514900df03d423",
              "IPY_MODEL_3f6b48595e0948b1acd08b74a6979736",
              "IPY_MODEL_302c0fea4449414fbf5c539ef6dc8f85"
            ],
            "layout": "IPY_MODEL_eea4129cf16a44cc8c35ea07659fd7e2"
          }
        },
        "a0acf96853034778bc514900df03d423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_697e982c959346a3b56ce430ae6c45aa",
            "placeholder": "​",
            "style": "IPY_MODEL_cb7992d5004345afa956604d5662eef1",
            "value": "Map: 100%"
          }
        },
        "3f6b48595e0948b1acd08b74a6979736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d09a0e3d0715422abc0dad94d3e0749a",
            "max": 1440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07a0a5cd39524fdc9be060455d767ad1",
            "value": 1440
          }
        },
        "302c0fea4449414fbf5c539ef6dc8f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a84c5c45e7a746b490b3d3d42feb0fc6",
            "placeholder": "​",
            "style": "IPY_MODEL_f071837b2c3c4017808d5772a062db07",
            "value": " 1440/1440 [00:00&lt;00:00, 2643.72 examples/s]"
          }
        },
        "eea4129cf16a44cc8c35ea07659fd7e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "697e982c959346a3b56ce430ae6c45aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb7992d5004345afa956604d5662eef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d09a0e3d0715422abc0dad94d3e0749a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a0a5cd39524fdc9be060455d767ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a84c5c45e7a746b490b3d3d42feb0fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f071837b2c3c4017808d5772a062db07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42690c4c62c348a08e7f1e33c96fb464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15f90db66fd1414c9d6ce347bd8c15dc",
              "IPY_MODEL_94d37c4a57194c76ab964736560c4cc0",
              "IPY_MODEL_350ff27bfda74ae59e27066f9aab2fab"
            ],
            "layout": "IPY_MODEL_053c0dd2aa884af1934478e55759a964"
          }
        },
        "15f90db66fd1414c9d6ce347bd8c15dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2047e76576e94e2391f6a151bc3af202",
            "placeholder": "​",
            "style": "IPY_MODEL_c26597426386489d8bbf7d845fd5942c",
            "value": "Map: 100%"
          }
        },
        "94d37c4a57194c76ab964736560c4cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c056be384a7a49bea820accd98daee29",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_542d844c273a425e9580d318d8a4f507",
            "value": 160
          }
        },
        "350ff27bfda74ae59e27066f9aab2fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b25f2e7fb2942d2b06dd7378c8bd13d",
            "placeholder": "​",
            "style": "IPY_MODEL_c3015b517fed4a0a967f2f8dae6c0e3a",
            "value": " 160/160 [00:00&lt;00:00, 1801.96 examples/s]"
          }
        },
        "053c0dd2aa884af1934478e55759a964": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2047e76576e94e2391f6a151bc3af202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26597426386489d8bbf7d845fd5942c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c056be384a7a49bea820accd98daee29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "542d844c273a425e9580d318d8a4f507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b25f2e7fb2942d2b06dd7378c8bd13d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3015b517fed4a0a967f2f8dae6c0e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aab292503c44dbca1b59a33b70b219c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebed4637eb2e4c6cb4a75f6c9e6bee10",
              "IPY_MODEL_50fb5056cf3a42a4ab63ade6c8acbbf0",
              "IPY_MODEL_6bdca25aa2fc4a908b8823414e9baa62"
            ],
            "layout": "IPY_MODEL_76976fd1c72c40e6b058c0c54886c780"
          }
        },
        "ebed4637eb2e4c6cb4a75f6c9e6bee10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d130087cbe474c4f93c123cf8118153f",
            "placeholder": "​",
            "style": "IPY_MODEL_de799ab5c53e4610a374756535db4c72",
            "value": "Map: 100%"
          }
        },
        "50fb5056cf3a42a4ab63ade6c8acbbf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c9165ed86d446159e42c4562f4cc739",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3aba5c403e54032a5cdad1b176d5746",
            "value": 400
          }
        },
        "6bdca25aa2fc4a908b8823414e9baa62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9390f7b988e74c629f32f8c5c36b1d77",
            "placeholder": "​",
            "style": "IPY_MODEL_688305d1bec341289d4bd0b3833fc36f",
            "value": " 400/400 [00:00&lt;00:00, 2242.91 examples/s]"
          }
        },
        "76976fd1c72c40e6b058c0c54886c780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d130087cbe474c4f93c123cf8118153f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de799ab5c53e4610a374756535db4c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c9165ed86d446159e42c4562f4cc739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3aba5c403e54032a5cdad1b176d5746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9390f7b988e74c629f32f8c5c36b1d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688305d1bec341289d4bd0b3833fc36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#installing required packages\n",
        "!pip install transformers datasets scikit-learn torch pandas matplotlib gradio -q\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import shutil\n",
        "import threading\n",
        "import time\n",
        "import traceback\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "# Import transformer libraries\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    pipeline,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset, DatasetDict\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "# ## Configuration\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "DATASET_FILENAME = 'dataset-tickets-multi-lang-4-20k.csv'\n",
        "TEXT_COLUMNS = ['subject', 'body']\n",
        "TARGET_COLUMN = 'queue'\n",
        "TEXT_FEATURE_COLUMN = 'text'  # Name for combined/cleaned text\n",
        "LABEL_COLUMN = 'label'        # Standard name for labels in datasets\n",
        "MODEL_OUTPUT_DIR = \"./ticket-classifier-model\"  # Directory to save fine-tuned model\n",
        "LABEL_MAPPING_DIR = MODEL_OUTPUT_DIR  # Save mappings with the model\n",
        "TEST_SET_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "MAX_TOKEN_LENGTH = 128  # Max length for tokenizer\n",
        "TRAIN_BATCH_SIZE = 16  # Adjust based on GPU memory\n",
        "EVAL_BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 1  # Use 1 for fast results, increase for better accuracy\n",
        "LEARNING_RATE = 2e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "# Enable development mode for faster training and less resource usage\n",
        "DEV_MODE = True  # Set to False for full training\n",
        "\n",
        "# Initialize global variables\n",
        "label2id = {}\n",
        "id2label = {}\n",
        "num_labels = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    \"\"\"Basic, language-agnostic text cleaning.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\säöüß]', '', text, flags=re.IGNORECASE)  # Keep German chars\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Safe training function to prevent KeyboardInterrupt\n",
        "def safe_train_with_timeout(trainer, timeout_minutes=15):\n",
        "    \"\"\"\n",
        "    Run the training process with a timeout to prevent KeyboardInterrupt and hanging\n",
        "    \"\"\"\n",
        "    print(f\"Starting training with {timeout_minutes} minute timeout safety...\")\n",
        "\n",
        "    result = [None]\n",
        "    exception = [None]\n",
        "    completed = [False]\n",
        "\n",
        "    def training_thread():\n",
        "        try:\n",
        "            result[0] = trainer.train()\n",
        "            completed[0] = True\n",
        "        except Exception as e:\n",
        "            exception[0] = e\n",
        "            print(f\"Training error: {e}\")\n",
        "\n",
        "    # Start the training in a separate thread\n",
        "    thread = threading.Thread(target=training_thread)\n",
        "    thread.daemon = True\n",
        "    thread.start()\n",
        "\n",
        "    # Monitor the training thread\n",
        "    timeout_seconds = timeout_minutes * 60\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Loop until training completes or times out\n",
        "    while thread.is_alive():\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        # Check if we've exceeded the timeout\n",
        "        if elapsed > timeout_seconds:\n",
        "            print(f\"Training timeout after {timeout_minutes} minutes.\")\n",
        "            return None\n",
        "\n",
        "        # Print progress updates\n",
        "        if int(elapsed) % 60 == 0 and int(elapsed) > 0:  # Every minute\n",
        "            minutes_elapsed = elapsed / 60\n",
        "            print(f\"Training in progress... {minutes_elapsed:.1f} minutes elapsed\")\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    # Check for errors\n",
        "    if exception[0]:\n",
        "        print(f\"Training encountered an error: {exception[0]}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "    if completed[0]:\n",
        "        print(\"Training completed successfully!\")\n",
        "\n",
        "    return result[0]\n",
        "\n",
        "# Function to get a smaller model for development\n",
        "def get_development_model_checkpoint():\n",
        "    \"\"\"Returns a smaller, faster model for development/testing\"\"\"\n",
        "    # Options in order of increasing size/quality\n",
        "    options = [\n",
        "        \"prajjwal1/bert-tiny\",         # 4.4M parameters - fastest\n",
        "        \"prajjwal1/bert-mini\",         # 11.3M parameters - small\n",
        "        \"distilbert-base-multilingual-cased\",  # ~66M parameters - good balance\n",
        "        \"bert-base-multilingual-cased\"  # 110M parameter model - original, slowest\n",
        "    ]\n",
        "\n",
        "    return options[0] if DEV_MODE else options[2]\n",
        "\n",
        "\n",
        "# ## Create Dummy Dataset\n",
        "#\n",
        "# This function creates a synthetic dataset for testing if you don't have real data:\n",
        "\n",
        "# %%\n",
        "def create_dummy_dataset(filename, num_samples=1000):\n",
        "    \"\"\"Creates a dummy dataset for testing if the actual dataset is not available.\"\"\"\n",
        "    print(f\"Creating dummy dataset at {filename} for testing purposes...\")\n",
        "\n",
        "    # Define some sample queues\n",
        "    queues = [\"technical_support\", \"billing\", \"account_management\", \"sales\", \"general_inquiry\"]\n",
        "\n",
        "    # Sample subjects and bodies for each queue\n",
        "    queue_templates = {\n",
        "        \"technical_support\": {\n",
        "            \"subjects\": [\n",
        "                \"Can't login\", \"App crashing\", \"Website error\", \"Connection issue\",\n",
        "                \"Password reset not working\", \"Software bug\", \"Installation problem\"\n",
        "            ],\n",
        "            \"bodies\": [\n",
        "                \"I can't log into my account\", \"The app keeps crashing when I try to use it\",\n",
        "                \"I'm getting an error when I try to access the website\",\n",
        "                \"My connection keeps dropping\", \"Password reset link doesn't work\",\n",
        "                \"There's a bug in the latest version\", \"Having trouble installing the software\"\n",
        "            ]\n",
        "        },\n",
        "        \"billing\": {\n",
        "            \"subjects\": [\n",
        "                \"Invoice question\", \"Billing error\", \"Payment issue\", \"Refund request\",\n",
        "                \"Subscription problem\", \"Pricing question\", \"Payment method update\"\n",
        "            ],\n",
        "            \"bodies\": [\n",
        "                \"I have a question about my recent invoice\", \"I think there's an error on my bill\",\n",
        "                \"My payment was declined\", \"I would like a refund for my purchase\",\n",
        "                \"Having issues with my subscription\", \"Can you explain the pricing?\",\n",
        "                \"Need to update my payment information\"\n",
        "            ]\n",
        "        },\n",
        "        \"account_management\": {\n",
        "            \"subjects\": [\n",
        "                \"Change email\", \"Update account details\", \"Close account\", \"Change password\",\n",
        "                \"Account verification\", \"Account access\", \"Profile update\"\n",
        "            ],\n",
        "            \"bodies\": [\n",
        "                \"I need to change my email address\", \"Please update my account information\",\n",
        "                \"I want to close my account\", \"Need to change my password\",\n",
        "                \"How do I verify my account?\", \"Cannot access my account\",\n",
        "                \"Need to update my profile\"\n",
        "            ]\n",
        "        },\n",
        "        \"sales\": {\n",
        "            \"subjects\": [\n",
        "                \"Product inquiry\", \"Purchase question\", \"Discount inquiry\", \"Enterprise plan\",\n",
        "                \"Upgrade options\", \"Product comparison\", \"Bulk order\"\n",
        "            ],\n",
        "            \"bodies\": [\n",
        "                \"I want to know more about your product\", \"Question about making a purchase\",\n",
        "                \"Are there any discounts available?\", \"Information about enterprise plans\",\n",
        "                \"Looking to upgrade my account\", \"How does your product compare to competitors?\",\n",
        "                \"Interested in placing a bulk order\"\n",
        "            ]\n",
        "        },\n",
        "        \"general_inquiry\": {\n",
        "            \"subjects\": [\n",
        "                \"General question\", \"Information request\", \"Help needed\", \"Contact info\",\n",
        "                \"Hours of operation\", \"Shipping info\", \"Return policy\"\n",
        "            ],\n",
        "            \"bodies\": [\n",
        "                \"I have a general question\", \"Can you provide more information?\",\n",
        "                \"I need help with something\", \"What is your contact information?\",\n",
        "                \"What are your hours of operation?\", \"Information about shipping\",\n",
        "                \"What is your return policy?\"\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Generate random data\n",
        "    import random\n",
        "    data = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        queue = random.choice(queues)\n",
        "        templates = queue_templates[queue]\n",
        "\n",
        "        subject = random.choice(templates[\"subjects\"])\n",
        "        body = random.choice(templates[\"bodies\"])\n",
        "\n",
        "        # Add some randomness to the text\n",
        "        if random.random() > 0.5:\n",
        "            subject += f\" #{random.randint(1000, 9999)}\"\n",
        "        if random.random() > 0.7:\n",
        "            body += f\". Reference ID: REF-{random.randint(10000, 99999)}\"\n",
        "\n",
        "        data.append({\n",
        "            \"subject\": subject,\n",
        "            \"body\": body,\n",
        "            \"queue\": queue\n",
        "        })\n",
        "\n",
        "    # Create DataFrame and save to CSV\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Created dummy dataset with {len(df)} samples across {len(queues)} queues.\")\n",
        "    return filename\n",
        "\n",
        "# Create dummy dataset if we don't have real data\n",
        "if not os.path.exists(DATASET_FILENAME):\n",
        "    print(f\"Dataset file '{DATASET_FILENAME}' not found. Creating dummy dataset...\")\n",
        "    create_dummy_dataset(DATASET_FILENAME, num_samples=2000)\n",
        "\n",
        "\n",
        "# ## Data Processing\n",
        "#\n",
        "# This class handles loading and preparing the ticket data:\n",
        "\n",
        "# %%\n",
        "class TicketDataProcessor:\n",
        "    \"\"\"Handles loading, cleaning, and preparing ticket data for transformers.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_path, text_cols, target_col):\n",
        "        self.csv_path = csv_path\n",
        "        self.text_cols = text_cols\n",
        "        self.target_col = target_col\n",
        "\n",
        "    def load_and_prepare(self):\n",
        "        \"\"\"Loads CSV, cleans text, creates labels, returns HF Dataset.\"\"\"\n",
        "        global label2id, id2label, num_labels\n",
        "\n",
        "        print(f\"Loading dataset from {self.csv_path}...\")\n",
        "        try:\n",
        "            df = pd.read_csv(self.csv_path)\n",
        "            print(f\"Loaded {len(df)} rows.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading CSV: {e}\")\n",
        "            return None\n",
        "\n",
        "        # Basic checks and preprocessing\n",
        "        if self.target_col not in df.columns:\n",
        "            print(f\"Error: Target column '{self.target_col}' not found.\")\n",
        "            return None\n",
        "\n",
        "        if not all(col in df.columns for col in self.text_cols):\n",
        "            print(f\"Error: One or more text columns not found.\")\n",
        "            return None\n",
        "\n",
        "        # Handle missing values and combine text\n",
        "        df.dropna(subset=[self.target_col], inplace=True)\n",
        "        df[TEXT_FEATURE_COLUMN] = df[self.text_cols].fillna('').agg(' '.join, axis=1)\n",
        "        df[TEXT_FEATURE_COLUMN] = df[TEXT_FEATURE_COLUMN].apply(clean_text)\n",
        "\n",
        "        # Create label mappings\n",
        "        unique_labels = sorted(df[self.target_col].unique().tolist())\n",
        "        num_labels = len(unique_labels)\n",
        "        label2id = {name: i for i, name in enumerate(unique_labels)}\n",
        "        id2label = {i: name for i, name in enumerate(unique_labels)}\n",
        "        print(f\"Found {num_labels} unique labels: {unique_labels}\")\n",
        "\n",
        "        # Convert the target column to numeric IDs\n",
        "        df[LABEL_COLUMN] = df[self.target_col].map(lambda x: label2id.get(x, 0))\n",
        "\n",
        "        # Keep only necessary columns\n",
        "        df = df[[TEXT_FEATURE_COLUMN, LABEL_COLUMN]]\n",
        "\n",
        "        # Convert to Hugging Face Dataset\n",
        "        raw_dataset = Dataset.from_pandas(df)\n",
        "\n",
        "        # Limit dataset size in development mode\n",
        "        if DEV_MODE:\n",
        "            max_samples = 2000\n",
        "            if len(raw_dataset) > max_samples:\n",
        "                indices = np.random.choice(len(raw_dataset), max_samples, replace=False)\n",
        "                raw_dataset = raw_dataset.select(indices)\n",
        "                print(f\"DEV MODE: Limited dataset to {max_samples} samples\")\n",
        "\n",
        "        # Split dataset\n",
        "        train_test_split = raw_dataset.train_test_split(\n",
        "            test_size=TEST_SET_SIZE,\n",
        "            seed=RANDOM_STATE\n",
        "        )\n",
        "        train_val_split = train_test_split['train'].train_test_split(\n",
        "            test_size=0.1,\n",
        "            seed=RANDOM_STATE\n",
        "        )\n",
        "\n",
        "        dataset_dict = DatasetDict({\n",
        "            'train': train_val_split['train'],\n",
        "            'validation': train_val_split['test'],\n",
        "            'test': train_test_split['test']\n",
        "        })\n",
        "\n",
        "        print(\"Dataset prepared and split:\")\n",
        "        for split, ds in dataset_dict.items():\n",
        "            print(f\"  {split}: {len(ds)} examples\")\n",
        "\n",
        "        return dataset_dict\n",
        "\n",
        "\n",
        "# ## Model Training\n",
        "#\n",
        "# This class handles the training process:\n",
        "\n",
        "# %%\n",
        "# Tokenizer function\n",
        "def tokenize_function(examples, tokenizer):\n",
        "    \"\"\"Tokenizes text data for sequence classification.\"\"\"\n",
        "    try:\n",
        "        if TEXT_FEATURE_COLUMN not in examples:\n",
        "            raise ValueError(f\"Text column '{TEXT_FEATURE_COLUMN}' not found.\")\n",
        "\n",
        "        texts = examples[TEXT_FEATURE_COLUMN]\n",
        "        if not texts or all(not text for text in texts):\n",
        "            raise ValueError(\"Input texts are empty or None\")\n",
        "\n",
        "        return tokenizer(\n",
        "            texts,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_TOKEN_LENGTH,\n",
        "            return_tensors=None\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error in tokenization: {e}\")\n",
        "        batch_size = len(examples[list(examples.keys())[0]])\n",
        "        return {\n",
        "            \"input_ids\": [[0] * 5] * batch_size,\n",
        "            \"attention_mask\": [[0] * 5] * batch_size\n",
        "        }\n",
        "\n",
        "# Metrics computation\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Computes metrics for sequence classification.\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average='macro', zero_division=0\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro\n",
        "    }\n",
        "\n",
        "# Trainer class\n",
        "class TicketTrainer:\n",
        "    \"\"\"Handles the training process using transformers.Trainer.\"\"\"\n",
        "    def __init__(self, model_checkpoint, dataset_dict, output_dir):\n",
        "        self.model_checkpoint = model_checkpoint\n",
        "        self.dataset_dict = dataset_dict\n",
        "        self.output_dir = output_dir\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        self.tokenized_datasets = None\n",
        "\n",
        "    def setup_trainer(self):\n",
        "        \"\"\"Loads tokenizer, model, tokenizes data, and configures Trainer.\"\"\"\n",
        "        global label2id, id2label, num_labels\n",
        "\n",
        "        if num_labels == 0 or not label2id or not id2label:\n",
        "            print(\"Error: Label mappings not initialized. Run data processing first.\")\n",
        "            return False\n",
        "\n",
        "        # Load tokenizer\n",
        "        print(f\"Loading tokenizer for '{self.model_checkpoint}'...\")\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_checkpoint)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading tokenizer: {e}\")\n",
        "            try:\n",
        "                self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "            except Exception:\n",
        "                return False\n",
        "\n",
        "        # Tokenize datasets\n",
        "        try:\n",
        "            def process_split(dataset, split_name):\n",
        "                print(f\"Tokenizing {split_name} split...\")\n",
        "                tokenized = dataset.map(\n",
        "                    lambda examples: tokenize_function(examples, self.tokenizer),\n",
        "                    batched=True,\n",
        "                    batch_size=32\n",
        "                )\n",
        "                if TEXT_FEATURE_COLUMN in tokenized.column_names:\n",
        "                    tokenized = tokenized.remove_columns([TEXT_FEATURE_COLUMN])\n",
        "                tokenized.set_format(\"torch\")\n",
        "                return tokenized\n",
        "\n",
        "            self.tokenized_datasets = DatasetDict({\n",
        "                split: process_split(dataset, split)\n",
        "                for split, dataset in self.dataset_dict.items()\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during dataset tokenization: {e}\")\n",
        "            return False\n",
        "\n",
        "        # Load model\n",
        "        print(f\"Loading model '{self.model_checkpoint}'...\")\n",
        "        try:\n",
        "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                self.model_checkpoint,\n",
        "                num_labels=num_labels,\n",
        "                id2label=id2label,\n",
        "                label2id=label2id,\n",
        "                ignore_mismatched_sizes=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            try:\n",
        "                fallback_model = \"prajjwal1/bert-tiny\" if DEV_MODE else \"bert-base-uncased\"\n",
        "                self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                    fallback_model,\n",
        "                    num_labels=num_labels,\n",
        "                    id2label=id2label,\n",
        "                    label2id=label2id,\n",
        "                    ignore_mismatched_sizes=True\n",
        "                )\n",
        "            except Exception:\n",
        "                return False\n",
        "\n",
        "        # Create training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=self.output_dir,\n",
        "            learning_rate=5e-5 if DEV_MODE else LEARNING_RATE,\n",
        "            per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
        "            per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
        "            num_train_epochs=1 if DEV_MODE else NUM_EPOCHS,\n",
        "            weight_decay=WEIGHT_DECAY,\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"f1_macro\",\n",
        "            push_to_hub=False,\n",
        "            fp16=torch.cuda.is_available(),\n",
        "            logging_dir=f'{self.output_dir}/logs',\n",
        "            logging_steps=100,\n",
        "            report_to=\"none\",\n",
        "            save_total_limit=1,\n",
        "            dataloader_num_workers=2 if DEV_MODE else 0,\n",
        "            disable_tqdm=False\n",
        "        )\n",
        "\n",
        "        # Initialize Trainer\n",
        "        callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "\n",
        "        try:\n",
        "            self.trainer = Trainer(\n",
        "                model=self.model,\n",
        "                args=training_args,\n",
        "                train_dataset=self.tokenized_datasets[\"train\"],\n",
        "                eval_dataset=self.tokenized_datasets[\"validation\"],\n",
        "                tokenizer=self.tokenizer,\n",
        "                data_collator=DataCollatorWithPadding(tokenizer=self.tokenizer),\n",
        "                compute_metrics=compute_metrics,\n",
        "                callbacks=callbacks\n",
        "            )\n",
        "            print(\"Trainer setup complete.\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up trainer: {e}\")\n",
        "            return False\n",
        "\n",
        "    def evaluate_on_test(self):\n",
        "        \"\"\"Evaluates the final model on the test set.\"\"\"\n",
        "        if not self.trainer or \"test\" not in self.tokenized_datasets:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            print(\"Evaluating model on the test set...\")\n",
        "            test_results = self.trainer.evaluate(self.tokenized_datasets[\"test\"])\n",
        "            return test_results\n",
        "        except Exception as e:\n",
        "            print(f\"Error during test evaluation: {e}\")\n",
        "            return None\n",
        "\n",
        "    def save_model_and_tokenizer(self):\n",
        "        \"\"\"Saves the fine-tuned model and tokenizer.\"\"\"\n",
        "        if not self.trainer:\n",
        "            return\n",
        "        try:\n",
        "            print(f\"Saving model and tokenizer to {self.output_dir}...\")\n",
        "            self.trainer.save_model(self.output_dir)\n",
        "            self.tokenizer.save_pretrained(self.output_dir)\n",
        "            print(\"Model and tokenizer saved.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving model: {e}\")\n",
        "\n",
        "\n",
        "# ## Utilities for Label Mappings\n",
        "\n",
        "# %%\n",
        "def save_label_mappings(output_dir):\n",
        "    \"\"\"Saves label2id and id2label mappings.\"\"\"\n",
        "    global label2id, id2label\n",
        "    if not label2id or not id2label:\n",
        "        print(\"Error: Label mappings not available to save.\")\n",
        "        return False\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    try:\n",
        "        with open(os.path.join(output_dir, \"label2id.json\"), 'w') as f:\n",
        "            json.dump(label2id, f, indent=2)\n",
        "        with open(os.path.join(output_dir, \"id2label.json\"), 'w') as f:\n",
        "            id2label_str = {str(k): v for k, v in id2label.items()}\n",
        "            json.dump(id2label_str, f, indent=2)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving label mappings: {e}\")\n",
        "        return False\n",
        "\n",
        "def load_label_mappings(input_dir):\n",
        "    \"\"\"Loads label2id and id2label mappings.\"\"\"\n",
        "    global label2id, id2label, num_labels\n",
        "    try:\n",
        "        path_l2i = os.path.join(input_dir, \"label2id.json\")\n",
        "        path_i2l = os.path.join(input_dir, \"id2label.json\")\n",
        "        if not os.path.exists(path_l2i) or not os.path.exists(path_i2l):\n",
        "            return False\n",
        "\n",
        "        with open(path_l2i, 'r') as f:\n",
        "            label2id = json.load(f)\n",
        "        with open(path_i2l, 'r') as f:\n",
        "            loaded_id2label = json.load(f)\n",
        "            id2label = {int(k): v for k, v in loaded_id2label.items()}\n",
        "\n",
        "        num_labels = len(label2id)\n",
        "        print(f\"Loaded {num_labels} label mappings.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading label mappings: {e}\")\n",
        "        return False\n",
        "\n",
        "def check_model_exists(model_dir):\n",
        "    \"\"\"Check if a trained transformer model exists and is valid.\"\"\"\n",
        "    if not os.path.isdir(model_dir):\n",
        "        return False, False\n",
        "    required_files = [\"config.json\", \"pytorch_model.bin\", \"tokenizer_config.json\"]\n",
        "    has_files = all(os.path.exists(os.path.join(model_dir, f)) for f in required_files)\n",
        "    has_mappings = os.path.exists(os.path.join(model_dir, \"label2id.json\"))\n",
        "    return True, (has_files and has_mappings)\n",
        "\n",
        "\n",
        "# ## Prediction Class\n",
        "\n",
        "# %%\n",
        "class TicketPredictor:\n",
        "    \"\"\"Handles prediction using a fine-tuned transformer model.\"\"\"\n",
        "    def __init__(self, model_path):\n",
        "        self.model_path = model_path\n",
        "        self.pipeline = None\n",
        "        self.id2label = None\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "\n",
        "        # First load the label mappings\n",
        "        if not load_label_mappings(self.model_path):\n",
        "            print(\"Warning: Failed to load label mappings.\")\n",
        "\n",
        "        try:\n",
        "            # Try loading as pipeline first\n",
        "            device = 0 if torch.cuda.is_available() else -1\n",
        "            self.pipeline = pipeline(\n",
        "                \"text-classification\",\n",
        "                model=self.model_path,\n",
        "                tokenizer=self.model_path,\n",
        "                device=device\n",
        "            )\n",
        "            self.id2label = self.pipeline.model.config.id2label\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing pipeline: {e}\")\n",
        "\n",
        "            # Fallback to loading model and tokenizer separately\n",
        "            try:\n",
        "                self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
        "                self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path)\n",
        "                self.id2label = self.model.config.id2label\n",
        "            except Exception as e2:\n",
        "                raise RuntimeError(\"Failed to initialize prediction\") from e2\n",
        "\n",
        "    def predict(self, text):\n",
        "        \"\"\"Predicts the queue for a given text.\"\"\"\n",
        "        if not text or not isinstance(text, str) or not text.strip():\n",
        "            return \"N/A\", 0.0, {}\n",
        "\n",
        "        try:\n",
        "            # Clean the input text\n",
        "            cleaned_text = clean_text(text)\n",
        "            if not cleaned_text:\n",
        "                return \"N/A\", 0.0, {}\n",
        "\n",
        "            # Get predictions\n",
        "            if self.pipeline:\n",
        "                try:\n",
        "                    results = self.pipeline(cleaned_text, return_all_scores=True)\n",
        "                except Exception:\n",
        "                    return \"Error\", 0.0, {}\n",
        "            else:\n",
        "                # Fallback to manual prediction\n",
        "                try:\n",
        "                    inputs = self.tokenizer(cleaned_text, return_tensors=\"pt\",\n",
        "                                           truncation=True, padding=True)\n",
        "                    with torch.no_grad():\n",
        "                        outputs = self.model(**inputs)\n",
        "\n",
        "                    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "                    probs = probs[0].tolist()\n",
        "\n",
        "                    results = [{\n",
        "                        'label': str(i),\n",
        "                        'score': prob\n",
        "                    } for i, prob in enumerate(probs)]\n",
        "                except Exception:\n",
        "                    return \"Error\", 0.0, {}\n",
        "\n",
        "            # Process results\n",
        "            if isinstance(results, list) and len(results) > 0:\n",
        "                scores_list = results[0] if isinstance(results[0], list) else results\n",
        "            else:\n",
        "                return \"Error\", 0.0, {}\n",
        "\n",
        "            # Extract probabilities and map labels\n",
        "            probabilities = {}\n",
        "            top_pred_label = \"Unknown\"\n",
        "            top_pred_score = 0.0\n",
        "\n",
        "            for item in scores_list:\n",
        "                if not isinstance(item, dict) or 'label' not in item or 'score' not in item:\n",
        "                    continue\n",
        "\n",
        "                label_str = item.get('label', '')\n",
        "                score = item.get('score', 0.0)\n",
        "\n",
        "                # Handle different label formats\n",
        "                queue_name = label_str\n",
        "\n",
        "                if label_str.startswith(\"LABEL_\"):\n",
        "                    try:\n",
        "                        label_id = int(label_str.split(\"_\")[1])\n",
        "                        if self.id2label and label_id in self.id2label:\n",
        "                            queue_name = self.id2label[label_id]\n",
        "                    except:\n",
        "                        pass\n",
        "                elif label_str.isdigit() and self.id2label and int(label_str) in self.id2label:\n",
        "                    queue_name = self.id2label[int(label_str)]\n",
        "\n",
        "                probabilities[queue_name] = score\n",
        "                if score > top_pred_score:\n",
        "                    top_pred_score = score\n",
        "                    top_pred_label = queue_name\n",
        "\n",
        "            return top_pred_label, top_pred_score, probabilities\n",
        "\n",
        "        except Exception:\n",
        "            return \"Error\", 0.0, {}\n",
        "\n",
        "\n",
        "# ## Gradio Interface\n",
        "\n",
        "# Fix for the Gradio interface configuration\n",
        "# Replace the create_gradio_interface function with this version:\n",
        "\n",
        "def create_gradio_interface(predictor):\n",
        "    \"\"\"Creates the Gradio web interface.\"\"\"\n",
        "    if not predictor:\n",
        "        return None\n",
        "\n",
        "    def predict_for_gradio(text_input):\n",
        "        \"\"\"Process prediction and create visualization.\"\"\"\n",
        "        if not text_input or not text_input.strip():\n",
        "            return \"Please enter some ticket text.\", None\n",
        "\n",
        "        try:\n",
        "            pred_label, pred_score, probabilities = predictor.predict(text_input)\n",
        "\n",
        "            if pred_label in (\"Error\", \"N/A\"):\n",
        "                return \"An error occurred or input was empty.\", None\n",
        "\n",
        "            output_md = f\"\"\"\n",
        "            ## Ticket Classification Results\n",
        "\n",
        "            **Predicted Queue:** `{pred_label}`\n",
        "\n",
        "            **Confidence:** {pred_score:.2%}\n",
        "            \"\"\"\n",
        "\n",
        "            # Generate visualization\n",
        "            try:\n",
        "                if probabilities and len(probabilities) > 0:\n",
        "                    # Sort and limit to top categories\n",
        "                    sorted_items = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
        "                    queues = [item[0] for item in sorted_items[:10]]  # Top 10 only\n",
        "                    scores = [item[1] for item in sorted_items[:10]]\n",
        "\n",
        "                    # Create plot\n",
        "                    fig, ax = plt.subplots(figsize=(8, min(8, max(4, len(queues) * 0.5))))\n",
        "                    bars = ax.barh(queues, scores, color='skyblue')\n",
        "                    ax.set_xlabel('Probability')\n",
        "                    ax.set_title('Prediction Probabilities')\n",
        "                    ax.set_xlim(0, 1)\n",
        "\n",
        "                    # Add labels\n",
        "                    for i, bar in enumerate(bars):\n",
        "                        width = bar.get_width()\n",
        "                        ax.text(min(width + 0.01, 0.95), bar.get_y() + bar.get_height()/2,\n",
        "                               f'{width:.1%}', va='center')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    prob_plot = fig\n",
        "                    plt.close(fig)\n",
        "                else:\n",
        "                    prob_plot = None\n",
        "            except Exception:\n",
        "                prob_plot = None\n",
        "\n",
        "            return output_md, prob_plot\n",
        "\n",
        "        except Exception:\n",
        "            return \"An error occurred during processing.\", None\n",
        "\n",
        "    # Create the interface - fixed flagging_mode parameter\n",
        "    interface = gr.Interface(\n",
        "        fn=predict_for_gradio,\n",
        "        inputs=gr.Textbox(\n",
        "            lines=8,\n",
        "            label=\"Ticket Text Input\",\n",
        "            placeholder=\"Enter support ticket subject and/or body here...\"\n",
        "        ),\n",
        "        outputs=[\n",
        "            gr.Markdown(label=\"Classification Results\"),\n",
        "            gr.Plot(label=\"Probability Distribution\")\n",
        "        ],\n",
        "        title=\"Support Ticket Queue Classifier\",\n",
        "        description=\"Predicts the appropriate queue for a support ticket.\",\n",
        "        examples=[\n",
        "            [\"Subject: Cannot login Body: My password reset link expired, please help me access my account.\"],\n",
        "            [\"Order #12345 not received yet, tracking shows stuck?\"],\n",
        "            [\"Subject: Billing inquiry Body: I believe I was overcharged on my last invoice.\"],\n",
        "            [\"How do I update my company address?\"],\n",
        "            [\"[fr] Sujet : Problème de connexion Corps : Impossible de me connecter à mon compte.\"]\n",
        "        ],\n",
        "        flagging_mode=\"never\",  # This is the corrected parameter (was allow_flagging=False)\n",
        "        analytics_enabled=False,\n",
        "        cache_examples=False,\n",
        "    )\n",
        "\n",
        "    interface.queue(max_size=1)\n",
        "    return interface\n",
        "\n",
        "\n",
        "\n",
        "# ## Training model and Prediction Pipeline\n",
        "\n",
        "def train_and_launch():\n",
        "    \"\"\"Run the complete training and prediction pipeline.\"\"\"\n",
        "    # Choose model\n",
        "    MODEL_CHECKPOINT = get_development_model_checkpoint()\n",
        "    print(f\"Using model: {MODEL_CHECKPOINT}\")\n",
        "\n",
        "    predictor = None\n",
        "    force_retrain = False  # Set to True to force retraining\n",
        "\n",
        "    # Check for existing model\n",
        "    exists, is_valid = check_model_exists(MODEL_OUTPUT_DIR)\n",
        "\n",
        "    if exists and is_valid and not force_retrain:\n",
        "        print(f\"✓ Valid model found. Loading for prediction.\")\n",
        "        try:\n",
        "            load_label_mappings(MODEL_OUTPUT_DIR)\n",
        "            predictor = TicketPredictor(MODEL_OUTPUT_DIR)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            exists, is_valid = False  # Mark for retraining\n",
        "            shutil.rmtree(MODEL_OUTPUT_DIR, ignore_errors=True)\n",
        "\n",
        "    if predictor is None:  # Need to train\n",
        "        if exists and not is_valid:\n",
        "            print(f\"Found incomplete model. Cleaning up and retraining...\")\n",
        "            shutil.rmtree(MODEL_OUTPUT_DIR, ignore_errors=True)\n",
        "\n",
        "        os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "        # Process data\n",
        "        data_processor = TicketDataProcessor(DATASET_FILENAME, TEXT_COLUMNS, TARGET_COLUMN)\n",
        "        dataset_dict = data_processor.load_and_prepare()\n",
        "\n",
        "        if dataset_dict is None:\n",
        "            print(\"Error: Failed to process data.\")\n",
        "            return None\n",
        "\n",
        "        # Save label mappings\n",
        "        save_label_mappings(MODEL_OUTPUT_DIR)\n",
        "\n",
        "        # Train model\n",
        "        print(\"\\nSetting up trainer...\")\n",
        "        ticket_trainer = TicketTrainer(MODEL_CHECKPOINT, dataset_dict, MODEL_OUTPUT_DIR)\n",
        "        if not ticket_trainer.setup_trainer():\n",
        "            print(\"Error: Failed to set up trainer.\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\nStarting training (with timeout protection)...\")\n",
        "        train_result = safe_train_with_timeout(ticket_trainer.trainer, timeout_minutes=15)\n",
        "\n",
        "        # Save model regardless of training completion\n",
        "        print(\"\\nSaving model...\")\n",
        "        ticket_trainer.save_model_and_tokenizer()\n",
        "        save_label_mappings(MODEL_OUTPUT_DIR)\n",
        "\n",
        "        # Evaluate if possible\n",
        "        try:\n",
        "            test_results = ticket_trainer.evaluate_on_test()\n",
        "            if test_results:\n",
        "                print(\"\\nTest metrics:\", test_results)\n",
        "        except Exception as e:\n",
        "            print(f\"Evaluation error: {e}\")\n",
        "\n",
        "        # Initialize predictor with trained model\n",
        "        try:\n",
        "            load_label_mappings(MODEL_OUTPUT_DIR)\n",
        "            predictor = TicketPredictor(MODEL_OUTPUT_DIR)\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing predictor: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Launch Gradio interface\n",
        "    if predictor:\n",
        "        print(\"\\nCreating Gradio interface...\")\n",
        "        interface = create_gradio_interface(predictor)\n",
        "        if interface:\n",
        "            print(\"\\nLaunching interface. Share=True will generate a public link.\")\n",
        "            return interface.launch(share=True, debug=False)\n",
        "        else:\n",
        "            print(\"Failed to create interface.\")\n",
        "    else:\n",
        "        print(\"No predictor available.\")\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "train_and_launch()\n",
        "\n",
        "\n",
        "\n",
        "def text_interface():\n",
        "    \"\"\"Run a simple text-based prediction interface.\"\"\"\n",
        "    MODEL_CHECKPOINT = get_development_model_checkpoint()\n",
        "\n",
        "\n",
        "    if os.path.exists(MODEL_OUTPUT_DIR):\n",
        "        try:\n",
        "            load_label_mappings(MODEL_OUTPUT_DIR)\n",
        "            predictor = TicketPredictor(MODEL_OUTPUT_DIR)\n",
        "\n",
        "            print(\"\\n=== Text-Based Prediction Interface ===\")\n",
        "            print(\"Type 'q' or 'quit' to exit\")\n",
        "\n",
        "            while True:\n",
        "                user_input = input(\"\\nEnter ticket text: \")\n",
        "\n",
        "                if user_input.lower() in ('q', 'quit', 'exit'):\n",
        "                    break\n",
        "\n",
        "                if not user_input.strip():\n",
        "                    print(\"Please enter some text.\")\n",
        "                    continue\n",
        "\n",
        "                print(\"Processing...\")\n",
        "                pred_label, pred_score, probabilities = predictor.predict(user_input)\n",
        "\n",
        "                if pred_label not in (\"Error\", \"N/A\"):\n",
        "                    print(f\"\\nPredicted Queue: {pred_label}\")\n",
        "                    print(f\"Confidence: {pred_score:.2%}\")\n",
        "\n",
        "\n",
        "                    if probabilities and len(probabilities) > 1:\n",
        "                        print(\"\\nTop Predictions:\")\n",
        "                        sorted_preds = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
        "                        for i, (queue, score) in enumerate(sorted_preds[:3]):\n",
        "                            print(f\"{i+1}. {queue}: {score:.2%}\")\n",
        "                else:\n",
        "                    print(f\"Prediction error: {pred_label}\")\n",
        "\n",
        "            print(\"Interface closed.\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        print(\"No model found. Please run training first.\")\n",
        "        return False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0a90900679a841458109f1dcb0f26a9c",
            "a0acf96853034778bc514900df03d423",
            "3f6b48595e0948b1acd08b74a6979736",
            "302c0fea4449414fbf5c539ef6dc8f85",
            "eea4129cf16a44cc8c35ea07659fd7e2",
            "697e982c959346a3b56ce430ae6c45aa",
            "cb7992d5004345afa956604d5662eef1",
            "d09a0e3d0715422abc0dad94d3e0749a",
            "07a0a5cd39524fdc9be060455d767ad1",
            "a84c5c45e7a746b490b3d3d42feb0fc6",
            "f071837b2c3c4017808d5772a062db07",
            "42690c4c62c348a08e7f1e33c96fb464",
            "15f90db66fd1414c9d6ce347bd8c15dc",
            "94d37c4a57194c76ab964736560c4cc0",
            "350ff27bfda74ae59e27066f9aab2fab",
            "053c0dd2aa884af1934478e55759a964",
            "2047e76576e94e2391f6a151bc3af202",
            "c26597426386489d8bbf7d845fd5942c",
            "c056be384a7a49bea820accd98daee29",
            "542d844c273a425e9580d318d8a4f507",
            "3b25f2e7fb2942d2b06dd7378c8bd13d",
            "c3015b517fed4a0a967f2f8dae6c0e3a",
            "6aab292503c44dbca1b59a33b70b219c",
            "ebed4637eb2e4c6cb4a75f6c9e6bee10",
            "50fb5056cf3a42a4ab63ade6c8acbbf0",
            "6bdca25aa2fc4a908b8823414e9baa62",
            "76976fd1c72c40e6b058c0c54886c780",
            "d130087cbe474c4f93c123cf8118153f",
            "de799ab5c53e4610a374756535db4c72",
            "8c9165ed86d446159e42c4562f4cc739",
            "c3aba5c403e54032a5cdad1b176d5746",
            "9390f7b988e74c629f32f8c5c36b1d77",
            "688305d1bec341289d4bd0b3833fc36f"
          ]
        },
        "id": "TZei4T9f5Mia",
        "outputId": "b3719740-a833-4d09-f7da-186d0a1c80f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model: prajjwal1/bert-tiny\n",
            "Found incomplete model. Cleaning up and retraining...\n",
            "Loading dataset from dataset-tickets-multi-lang-4-20k.csv...\n",
            "Loaded 20000 rows.\n",
            "Found 10 unique labels: ['Billing and Payments', 'Customer Service', 'General Inquiry', 'Human Resources', 'IT Support', 'Product Support', 'Returns and Exchanges', 'Sales and Pre-Sales', 'Service Outages and Maintenance', 'Technical Support']\n",
            "DEV MODE: Limited dataset to 2000 samples\n",
            "Dataset prepared and split:\n",
            "  train: 1440 examples\n",
            "  validation: 160 examples\n",
            "  test: 400 examples\n",
            "\n",
            "Setting up trainer...\n",
            "Loading tokenizer for 'prajjwal1/bert-tiny'...\n",
            "Tokenizing train split...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1440 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a90900679a841458109f1dcb0f26a9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing validation split...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42690c4c62c348a08e7f1e33c96fb464"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing test split...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aab292503c44dbca1b59a33b70b219c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model 'prajjwal1/bert-tiny'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-17-a8cbe71d7079>:517: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  self.trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer setup complete.\n",
            "\n",
            "Starting training (with timeout protection)...\n",
            "Starting training with 15 minute timeout safety...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 00:01, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.066205</td>\n",
              "      <td>0.268750</td>\n",
              "      <td>0.047072</td>\n",
              "      <td>0.029861</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed successfully!\n",
            "\n",
            "Saving model...\n",
            "Saving model and tokenizer to ./ticket-classifier-model...\n",
            "Model and tokenizer saved.\n",
            "Evaluating model on the test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test metrics: {'eval_loss': 2.0580272674560547, 'eval_accuracy': 0.305, 'eval_f1_macro': 0.0519369944657301, 'eval_precision_macro': 0.033888888888888885, 'eval_recall_macro': 0.1111111111111111, 'eval_runtime': 0.3531, 'eval_samples_per_second': 1132.756, 'eval_steps_per_second': 36.815, 'epoch': 1.0}\n",
            "Loaded 10 label mappings.\n",
            "Loaded 10 label mappings.\n",
            "\n",
            "Creating Gradio interface...\n",
            "\n",
            "Launching interface. Share=True will generate a public link.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://00fa84d3fba26877f0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://00fa84d3fba26877f0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}